<!DOCTYPE html>
<html lang="ar">
<head>
<meta charset="UTF-8">
<title>Face Tracking + Smart Alarm</title>

<style>
body{
  background:#000;
  color:#fff;
  text-align:center;
  font-family:Arial;
}

#wrap{
  position:relative;
  width:320px;
  margin:auto;
}

video, canvas{
  width:320px;
  border-radius:12px;
}

canvas{
  position:absolute;
  top:0;
  left:0;
}

#status{
  margin:10px;
  padding:8px;
  border-radius:8px;
  background:green;
}

button{
  padding:8px 16px;
  border-radius:8px;
}
</style>
</head>

<body>

<h3>ðŸ“· ØªØªØ¨Ø¹ Ø§Ù„ÙˆØ¬Ù‡ </h3>
<div id="status">ðŸŸ¢ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØ¬Ù‡</div>
<button id="start">ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§</button>

<div id="wrap">
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
</div>

<!-- MediaPipe -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusBox = document.getElementById("status");

let smoothBox=null;
let alarmCtx=null, oscillator=null;
let alarmOn=false;

const lerp=(a,b,t)=>a+(b-a)*t;

// ðŸ”” Ø¥Ù†Ø°Ø§Ø± Web Audio
function startAlarm(){
  if(alarmOn) return;
  alarmCtx = new (window.AudioContext || window.webkitAudioContext)();
  oscillator = alarmCtx.createOscillator();
  const gain = alarmCtx.createGain();

  oscillator.type = "sawtooth"; // Ù†ØºÙ…Ø© Ø¥Ù†Ø°Ø§Ø±
  oscillator.frequency.setValueAtTime(900, alarmCtx.currentTime);

  gain.gain.setValueAtTime(0.05, alarmCtx.currentTime);

  oscillator.connect(gain);
  gain.connect(alarmCtx.destination);

  oscillator.start();
  alarmOn=true;
}

function stopAlarm(){
  if(!alarmOn) return;
  oscillator.stop();
  alarmCtx.close();
  alarmOn=false;
}

const faceDetection = new FaceDetection({
  locateFile: f =>
    `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${f}`
});

faceDetection.setOptions({
  model:"short",
  minDetectionConfidence:0.6
});

faceDetection.onResults(results=>{
  ctx.clearRect(0,0,canvas.width,canvas.height);

  if(results.detections && results.detections.length){
    const r = results.detections[0].boundingBox;

    const box={
      x:r.xCenter*canvas.width-(r.width*canvas.width)/2,
      y:r.yCenter*canvas.height-(r.height*canvas.height)/2,
      w:r.width*canvas.width,
      h:r.height*canvas.height
    };

    if(!smoothBox) smoothBox={...box};
    else{
      smoothBox.x=lerp(smoothBox.x,box.x,0.3);
      smoothBox.y=lerp(smoothBox.y,box.y,0.3);
      smoothBox.w=lerp(smoothBox.w,box.w,0.3);
      smoothBox.h=lerp(smoothBox.h,box.h,0.3);
    }

    ctx.strokeStyle="red";
    ctx.lineWidth=3;
    ctx.strokeRect(
      smoothBox.x,
      smoothBox.y,
      smoothBox.w,
      smoothBox.h
    );

    statusBox.textContent="ðŸ”´ ÙˆØ¬Ù‡ Ù…ÙƒØªØ´Ù";
    statusBox.style.background="red";
    startAlarm();

  } else {
    smoothBox=null;
    statusBox.textContent="ðŸŸ¢ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØ¬Ù‡";
    statusBox.style.background="green";
    stopAlarm();
  }
});

document.getElementById("start").onclick = async ()=>{
  const stream = await navigator.mediaDevices.getUserMedia({
    video:{facingMode:"user"},
    audio:false
  });

  video.srcObject=stream;
  await video.play();

  canvas.width=video.videoWidth;
  canvas.height=video.videoHeight;

  const camera=new Camera(video,{
    onFrame:async()=>{
      await faceDetection.send({image:video});
    },
    width:canvas.width,
    height:canvas.height
  });

  camera.start();
};
</script>

</body>
</html>
